env: HalfCheetah-v2
version: normal
replay_buffer_size: 1000000
qf_kwargs:
  hidden_sizes: [256, 256]
policy_kwargs:
  hidden_sizes: [256, 256]
algorithm_kwargs:
  num_epochs: 1000
  num_eval_steps_per_epoch: 5000
  num_trains_per_train_loop: 3000
  num_expl_steps_per_train_loop: 3000
  min_num_steps_before_training: 10000
  max_path_length: 1000
  batch_size: 256
trainer_kwargs:
  discount: 0.99